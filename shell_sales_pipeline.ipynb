{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql import functions as F\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "# Parse job parameters\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "# Step 1: Load the data from S3 (specify the S3 path and data format)\n",
    "datasource = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"paths\": [\"s3://bucket-name/sales_data.csv\"]},\n",
    "    format=\"csv\",\n",
    "    format_options={\"withHeader\": True}\n",
    ")\n",
    "\n",
    "# Step 2: Convert the Glue DynamicFrame to a Spark DataFrame\n",
    "df = datasource.toDF()\n",
    "\n",
    "# Step 3: Remove duplicates (based on key columns)\n",
    "df_cleaned = df.dropDuplicates()\n",
    "\n",
    "# Step 4: Handle null values\n",
    "# Option 1: Drop rows with any null values\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "# Write out as a CSV file\n",
    "df_cleaned.write.mode(\"overwrite\").csv(\"s3://bucket-name/Cleaned_data\")\n",
    "\n",
    "# create a crawler and point the datsource to s3://crawlablebucketshell/Cleaned_data\n",
    "# Load data from Glue Data Catalog (replace 'your_database' and 'your_table' with actual values)\n",
    "data_source = glueContext.create_dynamic_frame.from_catalog(database=\"<crawler-db>\", table_name=\"crawler-table\")\n",
    "\n",
    "# Convert Glue DynamicFrame to Spark DataFrame\n",
    "df = data_source.toDF()\n",
    "\n",
    "# Print the schema to verify the column names\n",
    "df.printSchema()\n",
    "\n",
    "# PostgreSQL JDBC connection details\n",
    "jdbc_url = \"jdbc:postgresql://<db-endpoint>:<port>/your_database_name\";\n",
    "connection_properties = {\n",
    "    \"user\": \"\", #input postgres username\n",
    "    \"password\": \"\", #input password\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Transformations to map CSV columns to the required schema\n",
    "# Distributor Table\n",
    "distributor_df = df.select(\"DistributorID\",\"DistributorName\").distinct()\n",
    "\n",
    "# DC Table\n",
    "dc_df = df.select(\"DCNumber\", \"DCName\", \"DistributorName\",\"DistributorID\").distinct()\n",
    "\n",
    "# Sales Date Table\n",
    "sales_date_df = df.select(\"SalesMonth\", \"SalesDay\", \"SalesYear\", \"DateID\").distinct()\n",
    "\n",
    "# SKU Table\n",
    "sku_df = df.select(\"DistributorSKU\", \"ShellSKUNumber\", \"DistributorSKUDescription\",\"SKU_ID\").distinct()\n",
    "\n",
    "# Sales Table (Ensure correct column names based on CSV schema)\n",
    "sales_df = df.select(\n",
    "    \"DCNumber\", \n",
    "    \"SalesMonth\", \n",
    "    \"DistributorSKU\", \n",
    "    \"DFOAQuantity\", \n",
    "    \"non-dfoaquantity\",   # Ensure correct case-sensitive column name\n",
    "    \"UnitOfMeasure\",\n",
    "    \"DCID\",\n",
    "    \"DateID\",\n",
    "    \"SKU_ID\"\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "# Write DataFrames to PostgreSQL tables using JDBC\n",
    "\n",
    "# 1. Insert data into distributor_table\n",
    "distributor_df.write.jdbc(url=jdbc_url, table=\"distributor_table\", mode=\"append\", properties=connection_properties)\n",
    "\n",
    "# 2. Insert data into dc_table\n",
    "dc_df.write.jdbc(url=jdbc_url, table=\"dc_table\", mode=\"append\", properties=connection_properties)\n",
    "\n",
    "# 3. Insert data into sales_date_table\n",
    "sales_date_df.write.jdbc(url=jdbc_url, table=\"sales_date_table\", mode=\"append\", properties=connection_properties)\n",
    "\n",
    "# 4. Insert data into SKU table\n",
    "sku_df.write.jdbc(url=jdbc_url, table=\"sku\", mode=\"append\", properties=connection_properties)\n",
    "\n",
    "# 5. Insert data into sales_table\n",
    "sales_df.write.jdbc(url=jdbc_url, table=\"sales_table\", mode=\"append\", properties=connection_properties)\n",
    "\n",
    "# Commit the Glue job\n",
    "job.commit()\n",
    "\n",
    "# Commit the job\n",
    "job.commit()\n",
    "\n",
    "\n",
    "#### 0. SQL Queries to create Schema in postgres \n",
    "# CREATE TABLE distributor_table (\n",
    "#     DistributorID SERIAL PRIMARY KEY,\n",
    "#     DistributorName VARCHAR(255) NOT NULL\n",
    "# );\n",
    "\n",
    "# CREATE TABLE dc_table (\n",
    "#     DCNumber VARCHAR(100) NOT NULL,\n",
    "#     DCName VARCHAR(255) NOT NULL,\n",
    "#     DCID SERIAL PRIMARY KEY,\n",
    "#     DistributorID INT REFERENCES distributor_table(DistributorID)\n",
    "# );\n",
    "\n",
    "# CREATE TABLE sales_date_table (\n",
    "#     SalesMonth INT NOT NULL,\n",
    "#     SalesDay INT NOT NULL,\n",
    "#     SalesYear INT NOT NULL,\n",
    "#     DateID SERIAL PRIMARY KEY\n",
    "# );\n",
    "\n",
    "# CREATE TABLE SKU (\n",
    "#     DistributorSKU VARCHAR(100) NOT NULL,\n",
    "#     ShellSKUNumber INT NOT NULL,\n",
    "#     DistributorSKUDescription VARCHAR(255) NOT NULL,\n",
    "#     SKU_ID SERIAL PRIMARY KEY\n",
    "# );\n",
    "\n",
    "# CREATE TABLE sales_table (\n",
    "#     SaleID SERIAL PRIMARY KEY,\n",
    "#     DCID INT REFERENCES dc_table(DCID),\n",
    "#     DateID INT REFERENCES sales_date_table(DateID),\n",
    "#     SKU_ID INT REFERENCES SKU(SKU_ID),\n",
    "#     DFOAQuantity INT NOT NULL,\n",
    "#     NonDFOAQuantity INT NOT NULL,\n",
    "#     UnitOfMeasure VARCHAR(50) NOT NULL\n",
    "# );\n",
    "\n",
    "### 1.  Below are the SQL quries to execute to create indexes and materialized views for perfomance enhancement \n",
    "#  Index creation with correct case sensitivity\n",
    "# CREATE INDEX idx_dc_distributor_id ON dc_table (\"DistributorID\");\n",
    "# CREATE INDEX idx_sales_dcid ON sales_table (\"DCID\");\n",
    "# CREATE INDEX idx_sales_dateid ON sales_table (\"DateID\");\n",
    "# CREATE INDEX idx_sales_skuid ON sales_table (\"SKU_ID\");\n",
    "# CREATE INDEX idx_sales_date ON sales_date_table (\"SalesMonth\", \"SalesDay\", \"SalesYear\")\n",
    "\n",
    "#  Create a materialized view for total sales by DCID and SKU_ID\n",
    "# CREATE MATERIALIZED VIEW sales_summary AS\n",
    "# SELECT \n",
    "#     \"DCID\",\n",
    "#     \"SKU_ID\",\n",
    "#     SUM(\"DFOAQuantity\") AS total_dfoa_quantity,\n",
    "#     SUM(\"non-dfoaquantity\") AS total_non_dfoa_quantity,\n",
    "#     COUNT(*) AS total_sales\n",
    "# FROM \n",
    "#     sales_table\n",
    "# GROUP BY \n",
    "#     \"DCID\", \"SKU_ID\";\n",
    "\n",
    "\n",
    "#  Create an index on the materialized view to speed up queries\n",
    "# CREATE INDEX idx_sales_summary_dcid_skuid ON sales_summary (\"DCID\", \"SKU_ID\");\n",
    "#  Refresh the materialized view\n",
    "# REFRESH MATERIALIZED VIEW sales_summary;\n",
    "\n",
    "# 2. SQL Queries to address the questions raised by the team lead by Odette.\n",
    "#      a)  Calculate total sales revenue per product.\n",
    "#      SELECT \n",
    "#     s.\"SKU_ID\",\n",
    "#     sk.\"DistributorSKU\",\n",
    "#     SUM(s.\"DFOAQuantity\" + s.\"non-dfoaquantity\") * sk.\"Price\" AS total_revenue\n",
    "# FROM \n",
    "#     sales_table s\n",
    "# JOIN \n",
    "#     SKU sk ON s.\"SKU_ID\" = sk.\"SKU_ID\"\n",
    "# GROUP BY \n",
    "#     s.\"SKU_ID\", sk.\"DistributorSKU\"\n",
    "# ORDER BY \n",
    "#     total_revenue DESC;\n",
    "\n",
    "#      b) Determine the total quantity sold per customer.\n",
    "     \n",
    "#      SELECT \n",
    "#     s.\"DCID\",\n",
    "#     SUM(s.\"DFOAQuantity\" + s.\"non-dfoaquantity\") AS total_quantity_sold\n",
    "# FROM \n",
    "#     sales_table s\n",
    "# GROUP BY \n",
    "#     s.\"DCID\"\n",
    "# ORDER BY \n",
    "#     total_quantity_sold DESC;\n",
    "\n",
    "#      c)  Identify the top 5 products by revenue.\n",
    "     \n",
    "#      SELECT \n",
    "#     s.\"SKU_ID\",\n",
    "#     sk.\"DistributorSKU\",\n",
    "#     SUM(s.\"DFOAQuantity\" + s.\"non-dfoaquantity\") * sk.\"Price\" AS total_revenue\n",
    "# FROM \n",
    "#     sales_table s\n",
    "# JOIN \n",
    "#     SKU sk ON s.\"SKU_ID\" = sk.\"SKU_ID\"\n",
    "# GROUP BY \n",
    "#     s.\"SKU_ID\", sk.\"DistributorSKU\"\n",
    "# ORDER BY \n",
    "#     total_revenue DESC\n",
    "# LIMIT 5;\n",
    "\n",
    "\n",
    "#      d) Generate a monthly sales report showing total revenue and quantity sold.\n",
    "     \n",
    "#      SELECT \n",
    "#     DATE_TRUNC('month', DATE (s.\"SalesYear\" || '-' || s.\"SalesMonth\" || '-01')) AS sales_month,\n",
    "#     SUM(s.\"DFOAQuantity\" + s.\"non-dfoaquantity\") AS total_quantity_sold,\n",
    "#     SUM((s.\"DFOAQuantity\" + s.\"non-dfoaquantity\") * sk.\"Price\") AS total_revenue --make sure to get Price from Odette\n",
    "# FROM \n",
    "#     sales_table s\n",
    "# JOIN \n",
    "#     SKU sk ON s.\"SKU_ID\" = sk.\"SKU_ID\"\n",
    "# GROUP BY \n",
    "#     sales_month\n",
    "# ORDER BY \n",
    "#     sales_month;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
